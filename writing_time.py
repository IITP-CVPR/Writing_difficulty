# -*- coding: utf-8 -*-
"""Writing_time.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1wLpwbvwBi6BANLdbyDJEZAJBdohh3A8h
"""

import pandas as pd
import numpy as np
import random
import matplotlib.pyplot as plt

from sklearn.preprocessing import StandardScaler, PolynomialFeatures
from sklearn.linear_model import LinearRegression, Lasso, Ridge, ElasticNet
from sklearn.ensemble import (
    RandomForestRegressor,
    GradientBoostingRegressor,
    AdaBoostRegressor,
    VotingRegressor
)
from sklearn.neural_network import MLPRegressor
from sklearn.neighbors import KNeighborsRegressor
from sklearn.svm import SVR
from lightgbm import LGBMRegressor
import xgboost as xgb
from sklearn.pipeline import make_pipeline
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

# === Load data ===
data_path1 = "/content/drive/MyDrive/Sorted_time.xlsx"
data_path2 = "/content/drive/MyDrive/features_main.xlsx"
writing_times = pd.read_excel(data_path1)
user_info = pd.read_excel(data_path2)

# Ensure 106 writers
user_info = user_info.iloc[:106]
writer_ids = user_info['WriterId']

# === Standardize user features (excluding WriterId) ===
exclude_col = 'WriterId'
scaler = StandardScaler()
df_scaled = user_info.copy()
df_scaled[user_info.columns.difference([exclude_col])] = scaler.fit_transform(
    user_info[user_info.columns.difference([exclude_col])]
)
user_info = df_scaled

# === Prepare model dictionary ===
models = {
    'Polynomial': make_pipeline(PolynomialFeatures(3), LinearRegression()),  # cubic features
    'RandomForest': RandomForestRegressor(n_estimators=100, random_state=42),
    'XGBoost': xgb.XGBRegressor(random_state=42),
    'LinearRegression': LinearRegression(),
    'Lasso': Lasso(random_state=42),
    'Ridge': Ridge(random_state=42),
    'ElasticNet': ElasticNet(random_state=42),
    'MLP': MLPRegressor(random_state=42, max_iter=2000),
    'AdaBoost': AdaBoostRegressor(random_state=42),
    'KNN': KNeighborsRegressor(),
    'GradientBoosting': GradientBoostingRegressor(
        n_estimators=200, learning_rate=0.1, max_depth=3, random_state=42
    ),
    'LightGBM': LGBMRegressor(
        n_estimators=200, learning_rate=0.1, random_state=42
    ),
    'SVR': SVR(kernel='rbf', C=1.0, epsilon=0.1),
    'VotingEnsemble': VotingRegressor([
        ('gb', GradientBoostingRegressor(random_state=42)),
        ('rf', RandomForestRegressor(random_state=42)),
        ('xgb', xgb.XGBRegressor(random_state=42))
    ])
}

# === Split 30 words into 18:6:8 ===
words = list(writing_times.columns[1:31])  # assuming 30 word columns after first col
random.seed(42)
random.shuffle(words)
train_words = words[:18]
val_words = words[18:24]
test_words = words[24:32]

print(f"Train words: {len(train_words)}, Val words: {len(val_words)}, Test words: {len(test_words)}")

# === Aggregate X (features) and y (writing times) ===
X = user_info.drop(columns=['WriterId']).values

# Each model predicts writing time for each word (regression task)
results = {}

for model_name, model in models.items():
    preds_test_all = []
    true_test_all = []

    # Train separate model per word
    for word in train_words + val_words:
        y = writing_times[word].iloc[:106].values  # 106 writers
        model.fit(X, y)

    # Predict for test words
    for word in test_words:
        y_true = writing_times[word].iloc[:106].values
        y_pred = model.predict(X)

        preds_test_all.append(y_pred)
        true_test_all.append(y_true)

    preds_test_all = np.array(preds_test_all)
    true_test_all = np.array(true_test_all)

    # Average across 8 test words for each writer
    avg_pred = np.mean(preds_test_all, axis=0)
    avg_true = np.mean(true_test_all, axis=0)

    mse = mean_squared_error(avg_true, avg_pred)
    rmse = np.sqrt(mse)
    r2 = r2_score(avg_true, avg_pred)

    results[model_name] = {'RMSE': rmse, 'R2': r2}
    print(f"{model_name}: RMSE={rmse:.4f}, R²={r2:.4f}")

# === Find best model ===
best_model_name = max(results.items(), key=lambda x: x[1]['R2'])[0]
print(f"\nBest model based on R²: {best_model_name}")

# === Plot average writing time for 8 test words (best model) ===
best_model = models[best_model_name]
avg_pred = np.mean([best_model.fit(X, writing_times[word].iloc[:106]).predict(X) for word in test_words], axis=0)
avg_true = np.mean([writing_times[word].iloc[:106].values for word in test_words], axis=0)

# === REGRESSION PLOTS FOR ALL MODELS (SEPARATE FILES) ===
import os
from sklearn.linear_model import LinearRegression

plots_dir = "Regression_Plots_All_Models"
os.makedirs(plots_dir, exist_ok=True)

for name, model in models.items():
    try:

        model.fit(X, y_true)
        y_pred = model.predict(X)

        # Fit regression line: Predicted ~ Actual
        line_fit = LinearRegression()
        line_fit.fit(y_true.reshape(-1, 1), y_pred)
        line_x = np.linspace(y_true.min(), y_true.max(), 200)
        line_y = line_fit.predict(line_x.reshape(-1, 1))

        # Bounds for the identity line
        lo = float(min(y_true.min(), y_pred.min()))
        hi = float(max(y_true.max(), y_pred.max()))

        # Plot
        plt.figure(figsize=(7, 7))
        plt.scatter(y_true, y_pred, alpha=0.7, color = "blue")        # one dot per writer
        plt.plot([lo, hi], [lo, hi], linestyle="--", label="Theoritical diagonal", color= "red")
        plt.plot(line_x, line_y, linewidth=2, label="Regression", color="blue" )

        plt.xlabel("Actual", fontsize=30)
        plt.ylabel("Predicted", fontsize=30)
        #plt.title(f"Regression Plot — {name}")
        plt.xticks(fontsize=30)
        plt.yticks(fontsize=30)
        plt.legend(fontsize=20)
        plt.tight_layout()

        # Save figure
        fig_path = os.path.join(plots_dir, f"{name}_regression.png")
        plt.savefig(fig_path, dpi=300)
        plt.close()
        print(f"Saved plot: {fig_path}")

        # Also save actual vs predicted per writer
        out_csv = os.path.join(plots_dir, f"{name}_actual_vs_predicted.csv")
        pd.DataFrame({"Actual": y_true, "Predicted": y_pred}).to_csv(out_csv, index=False)
        print(f"Saved table: {out_csv}")

    except Exception as e:
        print(f"[WARN] Could not plot for {name}: {e}")